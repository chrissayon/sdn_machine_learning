{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_set_1_raw = np.genfromtxt('zodiac_attacked.csv', \n",
    "                             delimiter=',',\n",
    "                             skip_header=2)\n",
    "\n",
    "no_attack_set_1_raw = np.genfromtxt('zodiac_not_attacked.csv', \n",
    "                             delimiter=',',\n",
    "                             skip_header=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Clean up data (Remove flow count from data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_set_1 = np.take(attack_set_1_raw, [1,2,3,4,15], axis=1)\n",
    "no_attack_set_1 = np.take(no_attack_set_1_raw, [1,2,3,4,15], axis=1)\n",
    "training_set = np.concatenate((attack_set_1, no_attack_set_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.14870000e+04, 0.00000000e+00, 5.71780000e+04, 7.68000000e+02,\n",
       "        1.00102465e+01],\n",
       "       [8.14740000e+04, 1.00000000e+00, 1.05392000e+05, 2.05100000e+03,\n",
       "        1.00103073e+01],\n",
       "       [8.17790000e+04, 1.00000000e+00, 9.68790000e+04, 1.85600000e+03,\n",
       "        1.00102484e+01],\n",
       "       ...,\n",
       "       [5.23820000e+04, 2.69710000e+04, 6.00320000e+04, 5.44960000e+04,\n",
       "        1.00103407e+01],\n",
       "       [5.21710000e+04, 2.65700000e+04, 8.84520000e+04, 2.30360000e+04,\n",
       "        1.00102460e+01],\n",
       "       [5.25490000e+04, 2.68910000e+04, 3.63240000e+04, 1.77220000e+04,\n",
       "        1.00103118e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_set_1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes_set = np.zeros((len(no_attack_set_1),1))\n",
    "ones_set = np.ones((len(attack_set_1),1))\n",
    "target_set = np.concatenate((ones_set, zeroes_set), axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create type of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_size = 5\n",
    "output_size = 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(\n",
    "        5, \n",
    "        activation='relu', \n",
    "        input_shape=(input_size,),\n",
    "        kernel_initializer='glorot_normal',\n",
    "    ),\n",
    "#     tf.keras.layers.Dense(\n",
    "#         5, \n",
    "#         activation='relu',\n",
    "#     ),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                loss='binary_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Callbacks for model customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelStartedTime = datetime.datetime.now().strftime(\"%Y_%m_%dt%H_%M_%S\")\n",
    "\n",
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"adam_optimizer\",\n",
    "    \"loss_binary_crossentropy\"\n",
    "    # \"one_hidden_layer\",\n",
    "    \"two_hidden_layers\",\n",
    "    \"validation_split_0D1\",\n",
    "    modelStartedTime,\n",
    ")\n",
    "\n",
    "# log_dir = os.path.join(\n",
    "#     \"logs\",\n",
    "#     \"test\",\n",
    "#     modelStartedTime,\n",
    "# )\n",
    "\n",
    "callbacks = [\n",
    "    # tf.keras.callbacks.EarlyStopping(patience=50, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        \n",
    "        #update_freq='epoch'        \n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2338 samples, validate on 260 samples\n",
      "Epoch 1/20\n",
      "2338/2338 - 0s - loss: 3.5689 - accuracy: 0.8743 - val_loss: 1.9643 - val_accuracy: 0.7769\n",
      "Epoch 2/20\n",
      "2338/2338 - 0s - loss: 2.6707 - accuracy: 0.8725 - val_loss: 1.2349 - val_accuracy: 0.9500\n",
      "Epoch 3/20\n",
      "2338/2338 - 0s - loss: 2.7627 - accuracy: 0.8832 - val_loss: 1.2387 - val_accuracy: 0.9500\n",
      "Epoch 4/20\n",
      "2338/2338 - 0s - loss: 2.0019 - accuracy: 0.8854 - val_loss: 1.2651 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n",
      "2338/2338 - 0s - loss: 3.2443 - accuracy: 0.8708 - val_loss: 1.3712 - val_accuracy: 0.9077\n",
      "Epoch 6/20\n",
      "2338/2338 - 0s - loss: 1.8031 - accuracy: 0.8973 - val_loss: 1.4380 - val_accuracy: 0.7769\n",
      "Epoch 7/20\n",
      "2338/2338 - 0s - loss: 1.1809 - accuracy: 0.8905 - val_loss: 1.2022 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "2338/2338 - 0s - loss: 1.8057 - accuracy: 0.8935 - val_loss: 1.2122 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "2338/2338 - 0s - loss: 1.8603 - accuracy: 0.8926 - val_loss: 1.2791 - val_accuracy: 0.9077\n",
      "Epoch 10/20\n",
      "2338/2338 - 0s - loss: 2.5666 - accuracy: 0.8879 - val_loss: 1.1847 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "2338/2338 - 0s - loss: 2.1235 - accuracy: 0.8858 - val_loss: 1.0932 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "2338/2338 - 0s - loss: 4.1253 - accuracy: 0.8867 - val_loss: 1.1442 - val_accuracy: 0.9500\n",
      "Epoch 13/20\n",
      "2338/2338 - 0s - loss: 2.0254 - accuracy: 0.8725 - val_loss: 1.5108 - val_accuracy: 0.7885\n",
      "Epoch 14/20\n",
      "2338/2338 - 0s - loss: 5.5822 - accuracy: 0.8743 - val_loss: 2.5510 - val_accuracy: 0.7769\n",
      "Epoch 15/20\n",
      "2338/2338 - 0s - loss: 2.6612 - accuracy: 0.9033 - val_loss: 1.1992 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "2338/2338 - 0s - loss: 2.0878 - accuracy: 0.8922 - val_loss: 1.1584 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "2338/2338 - 0s - loss: 2.5557 - accuracy: 0.8867 - val_loss: 1.0701 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "2338/2338 - 0s - loss: 3.2945 - accuracy: 0.8901 - val_loss: 1.1268 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "2338/2338 - 0s - loss: 1.6031 - accuracy: 0.8837 - val_loss: 1.2552 - val_accuracy: 0.9077\n",
      "Epoch 20/20\n",
      "2338/2338 - 0s - loss: 2.6880 - accuracy: 0.8811 - val_loss: 1.1155 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc424f59c18>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_set, \n",
    "    target_set, \n",
    "    initial_epoch=0,\n",
    "    # initial_epoch=init_epoch-epoch_count,\n",
    "    epochs=20,\n",
    "    validation_split=0.1, \n",
    "    # batch_size=20, \n",
    "    verbose=2, \n",
    "    shuffle=True,\n",
    "    callbacks=callbacks, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('port_model_2.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.12517838, -0.03866845, -0.20502004, -0.75644237, -0.14499573],\n",
       "        [-0.19907333, -0.6377549 ,  0.41524097, -0.4151665 , -0.3867644 ],\n",
       "        [ 0.51228166, -0.16080315,  0.34544232,  0.06832434, -0.27374703],\n",
       "        [ 0.33012253, -0.7053988 ,  0.21261647, -0.65571713,  0.9632727 ],\n",
       "        [ 0.15257913,  0.05354644,  0.7596836 , -0.13905106, -0.12730189]],\n",
       "       dtype=float32),\n",
       " array([-0.22902527,  0.        ,  0.3487387 ,  0.        ,  0.37249017],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get output of model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Save Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-4b237b8aad4b>:1: export_saved_model (from tensorflow.python.keras.saving.saved_model_experimental) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `model.save(..., save_format=\"tf\")` or `tf.keras.models.save_model(..., save_format=\"tf\")`.\n",
      "WARNING:tensorflow:From /home/mint/Desktop/sdn_backend/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/mint/Desktop/sdn_backend/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: best_model_v22019_10_20t23_32_53.h5/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "tf.keras.experimental.export_saved_model(model, 'best_model_v2' + modelStartedTime + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('port_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('best_model_2019_10_20t21_32_39.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
